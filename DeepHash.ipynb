{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Deep Supervised Hashing\n",
    "While brushing up on algorithms I started to wonder if there was any research into estimating hash functions with Deep Learning. I discovered there has been a lot of interesting research, with much of it covered in [A Survey of Deep Hashing Methods (2022)](https://arxiv.org/pdf/2003.03369.pdf). In this notebook I implemented one supervised pairwise deep hashing methodology described in [Deep Supervised Hashing for Fast Image Retrieval (2016)](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_Deep_Supervised_Hashing_CVPR_2016_paper.pdf). The original model was developed using Caffe - how times have changed! In this notebook I use Tensorflow and make some minor changes to the original methodology, described below. Also I analyze the MNIST dataset to keep the analysis quick, since the primary purpose is to improve my understanding of image hashing and not push the limits of my GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from scipy.spatial.distance import hamming\n",
    "\n",
    "mnist = datasets.mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train, X_test = X_train/255, X_test/255\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_test = tf.expand_dims(X_test, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model structure\n",
    "I use a model structure similar to the one described in the paper. Since the MNIST I'm analyzing is simpler than CIFAR-10 data used in the paper my model contains one fewer convolutional layer and fewer filters per layer. Additionally my first fully connected layer has only 128 nodes and I generate 17 outputs - enough to encode roughly twice the number of images in my sample. Finally I use tanh activation for the final layer to approximate the quantization step. In total this model contains 9,137 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 24, 24, 12)        312       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 8, 8, 12)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 4, 4, 8)           2408      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_12 (Averag (None, 2, 2, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               4224      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 17)                2193      \n",
      "=================================================================\n",
      "Total params: 9,137\n",
      "Trainable params: 9,137\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(12, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((3, 3)))\n",
    "model.add(layers.Conv2D(8, (5, 5), activation='relu'))\n",
    "model.add(layers.AveragePooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(17, activation='tanh'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Estimation methodology\n",
    "I use the loss function described in the paper, except without regularization. For each batch I calculate the pairwise distance between each pair of hashes. If a pair of hashes shares a label, the distance should be low. If a pair of hashes have different labels, the distance should be high. Also the magnitude of the similarity between labels should be reflected in their respective hashes.\n",
    "\n",
    "I run 10 training epochs using the adam optimizer and a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 576.5067 - val_loss: 383.5576\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 361.9986 - val_loss: 331.0095\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 316.3627 - val_loss: 280.7243\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 266.4889 - val_loss: 232.8251\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 219.8488 - val_loss: 193.5880\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 176.7694 - val_loss: 152.6449\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 150.4059 - val_loss: 135.7185\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 133.3176 - val_loss: 119.4876\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 119.4915 - val_loss: 114.5700\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 113.1857 - val_loss: 109.3731\n"
     ]
    }
   ],
   "source": [
    "def deephashloss(y_true, y_pred):\n",
    "    m = 34\n",
    "    y_true = tf.cast(tf.equal(y_true, tf.transpose(y_true)), y_pred.dtype)\n",
    "    D = tf.reduce_sum((tf.expand_dims(y_pred, 1)-tf.expand_dims(y_pred, 0))**2,2) # pairwise distances\n",
    "    hashloss = tf.reduce_sum(tf.math.multiply(y_true, D) + tf.math.multiply(1-y_true, tf.maximum(m-D,0)), axis=1)\n",
    "    return hashloss*0.5\n",
    "\n",
    "model.compile(optimizer='adam', loss=deephashloss)\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model performance\n",
    "To evaluate model performance I evaluate the hashes among labels in the test sample. First I calculate the median hash within each label. Then I calculate the hamming distance between each pair of labels. I find that the hashes for images containing the number \"4\" and those containing the number \"9\" have the smallest hamming distance of 2. While those containing the number \"0\" and the number \"1\" have the highest hamming distance of 15. These results are consistent with my expectations about the relative similarity between the images of these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming distance (0, 1) = 15.0\n",
      "Hamming distance (4, 9) = 2.0\n"
     ]
    }
   ],
   "source": [
    "y_test_fit = model.predict(X_test)\n",
    "y_test_fit = np.where(y_test_fit>0,1,0)\n",
    "\n",
    "# compute median hash code for each label\n",
    "median_hash = [np.median(y_test_fit[y_test==n],axis=0) for n in range(10)]\n",
    "\n",
    "hash_distance = {}\n",
    "for i in range(10):\n",
    "    for j in range(i+1,10):\n",
    "        hash_distance[(i,j)] = hamming(median_hash[i],median_hash[j])*len(median_hash[i])\n",
    "\n",
    "print(\"Hamming distance\", max(hash_distance,key=hash_distance.get), \"=\", max(hash_distance.values()))\n",
    "print(\"Hamming distance\", min(hash_distance,key=hash_distance.get), \"=\", min(hash_distance.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('dsh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07cd6b3bf6831ada7c1005fddd050f453ad0beab5ad33c0ba1d2251ceb9f9f3f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
